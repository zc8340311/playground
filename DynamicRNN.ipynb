{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import itertools as ittls\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dynamic_RNN(object):\n",
    "    def __init__(self,seq_max_len,input_dim,hidden_size,class_num,dynamic=True):\n",
    "        self.seq_max_len = seq_max_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.class_num = class_num\n",
    "        \n",
    "        ## input place holder for the sequences and length for each tensor\n",
    "        self.seqlen = tf.placeholder(tf.int32, [None])\n",
    "        self.input_x = tf.placeholder(dtype = tf.float32, shape = [None, self.seq_max_len, self.input_dim])\n",
    "        self.label_y = tf.placeholder(dtype = tf.float32, shape = [None, self.class_num])\n",
    "        \n",
    "        self.softmax_weight = tf.Variable(tf.random_normal([self.hidden_size,self.class_num]))\n",
    "        self.softmax_bias = tf.Variable(tf.random_normal([self.class_num]))\n",
    "        self.lstm_cell = tf.contrib.rnn.BasicLSTMCell(self.hidden_size)\n",
    "\n",
    "        if dynamic:\n",
    "            x = tf.unstack(self.input_x, self.seq_max_len, 1)\n",
    "            outputs, states = tf.nn.dynamic_rnn(self.lstm_cell, self.input_x, dtype=tf.float32,\n",
    "                                    sequence_length=self.seqlen)\n",
    "        else:\n",
    "            x = tf.unstack(self.input_x, self.seq_max_len, 1)\n",
    "            outputs, states = tf.nn.static_rnn(self.lstm_cell, x, dtype=tf.float32,\n",
    "                                    sequence_length=self.seqlen)\n",
    "        outputs = tf.transpose(tf.stack(outputs), [1, 0, 2])\n",
    "        batch_size = tf.shape(outputs)[0]\n",
    "        index = tf.range(0, batch_size) * self.seq_max_len + (self.seqlen - 1)\n",
    "        self.outputs = tf.gather(tf.reshape(outputs, [-1, self.hidden_size]), index)\n",
    "        \n",
    "        logits = tf.matmul(self.outputs,self.softmax_weight) + self.softmax_bias\n",
    "        self.prediction = tf.nn.softmax(logits)\n",
    "        \n",
    "        correct_pred = tf.equal(tf.argmax(self.prediction,1),tf.argmax(self.label_y,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.inited = False\n",
    "        self.trained = False\n",
    "    \n",
    "    def fit(sess, x, y, batch_size, learning_rate=0.001, iteration = 500):\n",
    "        if not self.inited:\n",
    "            sess.run(self.init)\n",
    "            self.inited = False\n",
    "            \n",
    "tf.reset_default_graph()\n",
    "## Bug test\n",
    "seq_max_len = 10 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2\n",
    "dynamic = False\n",
    "with tf.Graph().as_default():\n",
    "    drnn = dynamic_RNN(seq_max_len= seq_max_len,input_dim=8,hidden_size=n_hidden,class_num=n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq_max_len = 10 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2\n",
    "dynamic = False\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        seqlen = tf.placeholder(tf.int32, [None])\n",
    "        input_x = tf.placeholder(\"float\", [None, seq_max_len, 8])\n",
    "        \n",
    "        lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "        if dynamic:\n",
    "            outputs, states = tf.nn.dynamic_rnn(lstm_cell, input_x, dtype=tf.float32,\n",
    "                                    sequence_length=seqlen)\n",
    "        else:\n",
    "            x = tf.unstack(input_x, seq_max_len, 1)\n",
    "            outputs, states = tf.nn.static_rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                    sequence_length=seqlen)\n",
    "        outputs = tf.transpose(tf.stack(outputs), [1, 0, 2])\n",
    "        batch_size = tf.shape(outputs)[0]\n",
    "        index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "        outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(2, 10, 8)\n",
    "X.reshape(-1,8).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = [10,9,8,7]\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        out_put = tf.constant(np.random.randn(4, 10, 8),dtype = tf.float32)\n",
    "        seqlen = tf.placeholder(tf.int32,[None])\n",
    "        print seqlen\n",
    "        fed_dict= {seqlen:seq}\n",
    "        index = tf.range(0,4) * 10 + (seqlen - 1)\n",
    "        print sess.run(tf.range(0,4) * 10 ,feed_dict=fed_dict)\n",
    "        print sess.run(seqlen-1,feed_dict=fed_dict)\n",
    "        print sess.run(index ,feed_dict = fed_dict)\n",
    "        reshape = tf.reshape(out_put,[-1,8])\n",
    "        print sess.run(tf.shape(reshape),feed_dict=fed_dict)\n",
    "        print sess.run(tf.gather(reshape,index),feed_dict=fed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
