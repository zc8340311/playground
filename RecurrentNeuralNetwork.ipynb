{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import itertools as ittls\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate batch index for loop interation\n",
    "def batch_gen(batch_size,polulation_size=500):\n",
    "    collection = []\n",
    "    for _ in ittls.cycle(xrange(polulation_size)):\n",
    "        collection.append(_)\n",
    "        if len(collection) >= batch_size:\n",
    "            yield collection\n",
    "            collection = []\n",
    "\n",
    "def mnist_encoder(y):\n",
    "    encoded_y = np.zeros((len(y),10),dtype=np.float32)\n",
    "    for index,label in enumerate(y):\n",
    "        encoded_y[index,label] = 1.0\n",
    "    return encoded_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "step: 1 ,batch_cost= 0.8882 ,accuray= 0.340\n",
      "step: 200 ,batch_cost= 0.6731 ,accuray= 0.580\n",
      "step: 400 ,batch_cost= 0.6656 ,accuray= 0.560\n",
      "step: 600 ,batch_cost= 0.6605 ,accuray= 0.580\n",
      "step: 800 ,batch_cost= 0.6568 ,accuray= 0.580\n",
      "step: 1000 ,batch_cost= 0.6540 ,accuray= 0.580\n",
      "step: 1200 ,batch_cost= 0.6519 ,accuray= 0.580\n",
      "step: 1400 ,batch_cost= 0.6502 ,accuray= 0.580\n",
      "step: 1600 ,batch_cost= 0.6488 ,accuray= 0.600\n",
      "step: 1800 ,batch_cost= 0.6477 ,accuray= 0.620\n",
      "step: 2000 ,batch_cost= 0.6466 ,accuray= 0.640\n",
      "step: 2200 ,batch_cost= 0.6458 ,accuray= 0.640\n",
      "step: 2400 ,batch_cost= 0.6450 ,accuray= 0.640\n",
      "step: 2600 ,batch_cost= 0.6443 ,accuray= 0.640\n",
      "step: 2800 ,batch_cost= 0.6436 ,accuray= 0.620\n",
      "step: 3000 ,batch_cost= 0.6431 ,accuray= 0.620\n",
      "step: 3200 ,batch_cost= 0.6425 ,accuray= 0.620\n",
      "step: 3400 ,batch_cost= 0.6421 ,accuray= 0.620\n",
      "step: 3600 ,batch_cost= 0.6416 ,accuray= 0.620\n",
      "step: 3800 ,batch_cost= 0.6412 ,accuray= 0.620\n",
      "step: 4000 ,batch_cost= 0.6409 ,accuray= 0.620\n",
      "step: 4200 ,batch_cost= 0.6405 ,accuray= 0.620\n",
      "step: 4400 ,batch_cost= 0.6402 ,accuray= 0.620\n",
      "step: 4600 ,batch_cost= 0.6399 ,accuray= 0.620\n",
      "step: 4800 ,batch_cost= 0.6397 ,accuray= 0.620\n",
      "step: 5000 ,batch_cost= 0.6394 ,accuray= 0.620\n"
     ]
    }
   ],
   "source": [
    "class basic_LSTM(object):\n",
    "    def __init__(self, sess, time_step, input_dim, hidden_size, class_num, batch_size):\n",
    "        self.time_step = time_step\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.class_num = class_num\n",
    "        self.batch_size = batch_size\n",
    "        self.rnn_cell = tf.contrib.rnn.BasicLSTMCell(hidden_size)\n",
    "        \n",
    "        self.input_x = tf.placeholder(dtype = tf.float32, shape = [None,time_step,input_dim])\n",
    "        self.label_y = tf.placeholder(dtype = tf.float32, shape = [None, class_num])\n",
    "        \n",
    "        state = self.rnn_cell.zero_state(batch_size = self.batch_size, dtype = tf.float32)\n",
    "        \n",
    "        self.output_list = []\n",
    "        for each_time_step in tf.unstack(self.input_x, time_step, axis=1):\n",
    "            output, state = self.rnn_cell(each_time_step, state)\n",
    "            self.output_list.append(output)\n",
    "        self.softmax_weight = tf.Variable(tf.random_normal([self.hidden_size,self.class_num]))\n",
    "        self.softmax_bias = tf.Variable(tf.random_normal([self.class_num]))\n",
    "        logits = tf.matmul(self.output_list[-1],self.softmax_weight) + self.softmax_bias\n",
    "        \n",
    "        self.prediction = tf.nn.softmax(logits)\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=self.label_y))\n",
    "        \n",
    "        correct_pred = tf.equal(tf.argmax(self.prediction,1),tf.argmax(self.label_y,1))\n",
    "        self.accuray = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        self.trained = False\n",
    "        \n",
    "    def batch_gen(self,batch_size,polulation_size=500):\n",
    "        collection = []\n",
    "        for _ in ittls.cycle(xrange(polulation_size)):\n",
    "            collection.append(_)\n",
    "            if len(collection) >= batch_size:\n",
    "                yield collection\n",
    "                collection = []\n",
    "\n",
    "    def fit(self, sess, x, y, learning_rate = 0.1,iterations=1000):\n",
    "        \"\"\"training process: create optimizer and perform training loop\"\"\"\n",
    "        assert x.shape[1:] == self.input_x.shape[1:]\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(self.cost)\n",
    "        \n",
    "        index_gen = self.batch_gen(batch_size = self.batch_size, polulation_size=x.shape[0])\n",
    "        cost_list = []\n",
    "        for step in xrange(1,iterations+1):\n",
    "            index = next(index_gen)\n",
    "            feed_x = x[index]\n",
    "            feed_y = y[index]\n",
    "            cost,_ = sess.run([self.cost,train_op],feed_dict={self.input_x:feed_x, self.label_y:feed_y})\n",
    "            cost_list.append(cost)\n",
    "            if step % 200 == 0 or step==1 or step==iterations:\n",
    "                cost,acc = sess.run([self.cost,self.accuray],\n",
    "                                    feed_dict={self.input_x:feed_x, self.label_y:feed_y})\n",
    "                print \"step:\",step,\",batch_cost=\",\"{:.4f}\".format(cost),\",accuray=\",\"{:.3f}\".format(acc)\n",
    "        self.trained = True\n",
    "        \n",
    "    def predict(sess, x):\n",
    "        pass\n",
    "with tf.Graph().as_default():\n",
    "    with tf.Session() as sess:\n",
    "        x = np.random.random((1000,10,15))\n",
    "        y = np.random.binomial(n=1, p=0.4, size=(1000,1))\n",
    "        encoded_y = np.zeros((len(y),2),dtype=np.float32)\n",
    "        for index,label in enumerate(y):\n",
    "            encoded_y[index,label] = 1.0\n",
    "        print y.shape\n",
    "        lstm = basic_LSTM(sess=sess, time_step= 10, input_dim = 15, hidden_size = 200, class_num = 2, batch_size = 50)\n",
    "        lstm.fit(sess=sess, x=x, y=encoded_y, learning_rate = 0.001,iterations=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = '142857'\n",
    "s2 = '769230'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
