{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from util import ImShow as I\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import precision_score as precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(l, n):\n",
    "    \"\"\"Yield successive n-sized batches from l, the last batch is the left indexes.\n",
    "        and n-sized batch index from l with replacement\n",
    "    \"\"\"\n",
    "    for i in xrange(0, l, n):\n",
    "        yield range(i,min(l,i+n)), np.random.choice(l, size= min(n,l-i))\n",
    "\n",
    "class Fluent_Autoencoder(object):\n",
    "    def __init__(self, sess, input_dim_list=[784,400],learning_rate=0.15):\n",
    "        \"\"\"input_dim_list must include the original data dimension\"\"\"\n",
    "        assert len(input_dim_list) >= 2\n",
    "        self.W_list = []\n",
    "        self.encoding_b_list = []\n",
    "        self.decoding_b_list = []\n",
    "        self.dim_list = input_dim_list\n",
    "        ## Encoders parameters\n",
    "        for i in range(len(input_dim_list)-1):\n",
    "            init_max_value = np.sqrt(6. / (self.dim_list[i] + self.dim_list[i+1]))\n",
    "            self.W_list.append(tf.Variable(tf.random_uniform([self.dim_list[i],self.dim_list[i+1]],\n",
    "                                                             np.negative(init_max_value),init_max_value)))\n",
    "            self.encoding_b_list.append(tf.Variable(tf.random_uniform([self.dim_list[i+1]],-0.1,0.1)))\n",
    "        ## Decoders parameters\n",
    "        for i in range(len(input_dim_list)-2,-1,-1):\n",
    "            self.decoding_b_list.append(tf.Variable(tf.random_uniform([self.dim_list[i]],-0.1,0.1)))\n",
    "        ## Placeholder for input\n",
    "        self.input_x = tf.placeholder(tf.float32,[None,self.dim_list[0]])\n",
    "        self.input_y = tf.placeholder(tf.float32,[None,self.dim_list[0]])\n",
    "        ## coding graph :\n",
    "        last_layer = self.input_x\n",
    "        for weight,bias in zip(self.W_list,self.encoding_b_list):\n",
    "            hidden = tf.sigmoid(tf.matmul(last_layer,weight) + bias)\n",
    "            last_layer = hidden\n",
    "        self.hidden = hidden \n",
    "        ## decode graph:\n",
    "        for weight,bias in zip(reversed(self.W_list),self.decoding_b_list):\n",
    "            hidden = tf.sigmoid(tf.matmul(last_layer,tf.transpose(weight)) + bias)\n",
    "            last_layer = hidden\n",
    "        self.recon = last_layer\n",
    "        self.cost = tf.reduce_mean(tf.square(self.recon - self.input_y))\n",
    "        #self.cost = tf.losses.log_loss(self.recon, self.input_x)\n",
    "        self.train_step = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(self.cost)\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def fit(self, X, sess, iteration=200, batch_size=50, init=False,verbose=False):\n",
    "        assert X.shape[1] == self.dim_list[0]\n",
    "        if init:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        sample_size = X.shape[0]\n",
    "        for i in xrange(iteration):\n",
    "            for one_batch,random_batch in batches(sample_size, batch_size):\n",
    "                sess.run(self.train_step,feed_dict = {self.input_x:X[one_batch],self.input_y:X[random_batch]})\n",
    "            if verbose and i%20==0:\n",
    "                e = self.cost.eval(session = sess,feed_dict = {self.input_x: X[one_batch],self.input_y:X[random_batch]})\n",
    "                print \"    iteration : \", i ,\", cost : \", e\n",
    "\n",
    "    def transform(self, X, sess):\n",
    "        return self.hidden.eval(session = sess, feed_dict={self.input_x: X})\n",
    "\n",
    "    def getRecon(self, X, sess):\n",
    "        return self.recon.eval(session = sess,feed_dict={self.input_x: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.load(r\"./data/4_other_x.npk\")[:500]\n",
    "# start_time = time.time()\n",
    "# with tf.Graph().as_default():\n",
    "#     with tf.Session() as sess:\n",
    "#         ae = Fluent_Autoencoder(sess = sess, input_dim_list=[784,500,400],learning_rate=0.0001)\n",
    "#         error = ae.fit(x ,sess = sess, batch_size = 500, iteration = 3000, verbose=True)\n",
    "#         R = ae.getRecon(x, sess = sess)\n",
    "\n",
    "#         error = ae.fit(x ,sess = sess,  batch_size = 500, iteration = 3000, verbose=True)\n",
    "#         R1 = ae.getRecon(x, sess = sess)\n",
    "#         print \"Runing time:\" + str(time.time() - start_time) + \" s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xpic = I.tile_raster_images(X = x, img_shape=(28,28), tile_shape=(10,10))\n",
    "# plt.imshow(Xpic,cmap='gray')\n",
    "# plt.show()\n",
    "# Rpic = I.tile_raster_images(X = R, img_shape=(28,28), tile_shape=(10,10))\n",
    "# plt.imshow(Rpic,cmap='gray')\n",
    "# plt.show()\n",
    "# R1pic = I.tile_raster_images(X = R1, img_shape=(28,28), tile_shape=(10,10))\n",
    "# plt.imshow(R1pic,cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shrink import l21shrink as SHR \n",
    "\n",
    "class RobustL21Autoencoder(object):\n",
    "    \"\"\"\n",
    "    @author: Chong Zhou\n",
    "    first version.\n",
    "    complete: 10/20/2016\n",
    "    Des:\n",
    "        X = L + S\n",
    "        L is a non-linearly low dimension matrix and S is a sparse matrix.\n",
    "        argmin ||L - Decoder(Encoder(L))|| + ||S||_2,1\n",
    "        Use Alternating projection to train model\n",
    "        The idea of shrink the l21 norm comes from the wiki 'Regularization' link: {\n",
    "            https://en.wikipedia.org/wiki/Regularization_(mathematics)\n",
    "        }\n",
    "    Improve:\n",
    "        1. fix the 0-cost bugs\n",
    "    \"\"\"\n",
    "    def __init__(self, sess, layers_sizes, lambda_=1.0, learning_rate = 0.01):\n",
    "        \"\"\"\n",
    "        sess: a Tensorflow tf.Session object\n",
    "        layers_sizes: a list that contain the deep ae layer sizes, including the input layer\n",
    "        lambda_: tuning the weight of l1 penalty of S\n",
    "        error: converge criterior for jump out training iteration\n",
    "        \"\"\"\n",
    "        self.lambda_ = lambda_\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.errors=[]\n",
    "        #self.AE = DAE.Deep_Autoencoder( sess = sess, input_dim_list = self.layers_sizes)\n",
    "        self.AE = Fluent_Autoencoder( sess = sess, \n",
    "                                     input_dim_list = self.layers_sizes,\n",
    "                                    learning_rate = learning_rate)\n",
    "        \n",
    "\n",
    "    def fit(self, X, sess, learning_rate=0.15, inner_iteration = 50,\n",
    "            iteration=20, batch_size=133, re_init = False,verbose=False):\n",
    "        ## The first layer must be the input layer, so they should have same sizes.\n",
    "        assert X.shape[1] == self.layers_sizes[0]\n",
    "        ## initialize L, S\n",
    "        self.L = np.zeros(X.shape)\n",
    "        self.S = np.zeros(X.shape)\n",
    "        ##LS0 = self.L + self.S\n",
    "        ## To estimate the size of input X\n",
    "        if verbose:\n",
    "            print \"X shape: \", X.shape\n",
    "            print \"L shape: \", self.L.shape\n",
    "            print \"S shape: \", self.S.shape\n",
    "\n",
    "        for it in xrange(iteration):\n",
    "            if verbose:\n",
    "                print \"Out iteration: \" , it\n",
    "            ## alternating project, first project to L\n",
    "            self.L = X - self.S\n",
    "            ## Using L to train the auto-encoder\n",
    "            self.AE.fit(self.L, sess = sess,\n",
    "                        iteration = inner_iteration,\n",
    "                        batch_size = batch_size,\n",
    "                        init = re_init,\n",
    "                        verbose = verbose)\n",
    "            ## get optmized L\n",
    "            self.L = self.AE.getRecon(X = self.L, sess = sess)\n",
    "            ## alternating project, now project to S and shrink S\n",
    "            self.S = SHR.l21shrink(self.lambda_, (X - self.L).T).T\n",
    "        return self.L , self.S\n",
    "    def transform(self, X, sess):\n",
    "        L = X - self.S\n",
    "        return self.AE.transform(X = L, sess = sess)\n",
    "    def getRecon(self, X, sess):\n",
    "        return self.AE.getRecon(self.L, sess = sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_run(lam):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            rae = RobustL21Autoencoder(sess = sess, lambda_= lam, \n",
    "                                       layers_sizes=[x.shape[1],int(x.shape[1]*0.5),int(x.shape[1]*0.25)],\n",
    "                                      learning_rate = 0.01)\n",
    "            L, S = rae.fit(x, sess = sess, \n",
    "                           inner_iteration = 50, \n",
    "                           iteration = 10,\n",
    "                           re_init = True,\n",
    "                           verbose = False)\n",
    "    return L,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 939, 0: 61})\n",
      "number of majority: 939\n",
      "number of outlier: 61\n",
      "outlier ratio: 0.061\n",
      "Counter({'m': 939, 'o': 61})\n"
     ]
    }
   ],
   "source": [
    "size = 1000\n",
    "x = np.load(r\"./data/4_other_x.npk\")[:size]\n",
    "y = np.load(r\"./data/4_other_y.npk\")[:size]\n",
    "stat = Counter(y)\n",
    "print stat\n",
    "print \"number of majority:\", stat[1]\n",
    "print \"number of outlier:\", len(y) - stat[1]\n",
    "print \"outlier ratio:\", (len(y) - stat[1])/ float(len(y))\n",
    "def binary_error(value):\n",
    "    if value != 0.0:\n",
    "        return \"o\" # 'majority'\n",
    "    else:\n",
    "        return \"m\" #'outlier'\n",
    "    \n",
    "def binary_y(value):\n",
    "    if value == 1:\n",
    "        return \"m\"\n",
    "    else:\n",
    "        return \"o\"\n",
    "\n",
    "bi_y = map(binary_y,y)\n",
    "print Counter(bi_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.  6.3 6.6 6.9 7.2 7.5 7.8 8.1 8.4 8.7 9.  9.3 9.6 9.9]\n",
      "lambda: 6.0\n",
      "stat: Counter({'o': 625, 'm': 375})\n",
      "precision 0.0944\n",
      "recall 0.9672131147540983\n",
      "f1 0.17201166180758018\n",
      "------------\n",
      "lambda: 6.3\n",
      "stat: Counter({'m': 503, 'o': 497})\n",
      "precision 0.11871227364185111\n",
      "recall 0.9672131147540983\n",
      "f1 0.2114695340501792\n",
      "------------\n",
      "lambda: 6.6\n",
      "stat: Counter({'m': 620, 'o': 380})\n",
      "precision 0.1368421052631579\n",
      "recall 0.8524590163934426\n",
      "f1 0.23582766439909297\n",
      "------------\n",
      "lambda: 6.8999999999999995\n",
      "stat: Counter({'m': 735, 'o': 265})\n",
      "precision 0.18490566037735848\n",
      "recall 0.8032786885245902\n",
      "f1 0.3006134969325153\n",
      "------------\n",
      "lambda: 7.199999999999999\n",
      "stat: Counter({'m': 783, 'o': 217})\n",
      "precision 0.17972350230414746\n",
      "recall 0.639344262295082\n",
      "f1 0.28057553956834536\n",
      "------------\n",
      "lambda: 7.499999999999999\n",
      "stat: Counter({'m': 861, 'o': 139})\n",
      "precision 0.2446043165467626\n",
      "recall 0.5573770491803278\n",
      "f1 0.33999999999999997\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "precisions=[]\n",
    "lams=[]\n",
    "recalls=[]\n",
    "f1s = []\n",
    "lam_list = np.arange(6.0,10.0,0.3)\n",
    "print lam_list\n",
    "for i,lam in enumerate(lam_list):\n",
    "    L,S = one_run(lam=lam)\n",
    "    predictions = map(binary_error,np.linalg.norm(S,axis = 1))\n",
    "    p = precision(bi_y,predictions,labels=[\"o\",\"m\"],pos_label=\"o\")\n",
    "    r = recall(bi_y,predictions,labels=[\"o\",\"m\"],pos_label=\"o\")\n",
    "    f1 = f1_score(bi_y,predictions,labels=[\"o\",\"m\"],pos_label=\"o\")\n",
    "    print \"lambda:\", lam\n",
    "    print \"stat:\", Counter(predictions)\n",
    "    print \"precision\",p\n",
    "    print \"recall\",r\n",
    "    print \"f1\",f1\n",
    "    lams.append(lam)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    f1s.append(f1)\n",
    "#     print CM(bi_y,predictions)\n",
    "    print \"------------\"\n",
    "print len(lams),len(recalls),len(f1s),len(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
